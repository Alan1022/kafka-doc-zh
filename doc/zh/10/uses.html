<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<p>以下描述了一些 ApacheKafka &reg;的流行用例。有关这些领域的概述，请参阅 <a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying/">此博客中的文章</a>。 </p>

<h4><a id="uses_messaging" href="#uses_messaging">消息</a></h4>
Kafka 很好地替代了传统的message broker（消息代理）。
Message brokers 可用于各种场合（如将数据生成器与数据处理解耦，缓冲未处理的消息等）。
与大多数消息系统相比，Kafka拥有更好的吞吐量、内置分区、具有复制和容错的功能，这使它成为一个非常理想的大型消息处理应用。
<p>
根据我们的经验，通常消息传递使用较低的吞吐量，但可能要求较低的端到端延迟，Kafka提供强大的持久性来满足这一要求。
<p>
 在这方面，Kafka 可以与传统的消息传递系统（<a href="http://activemq.apache.org">ActiveMQ</a> 和
<a href="https://www.rabbitmq.com">RabbitMQ</a>）相媲美。

<h4><a id="uses_website" href="#uses_website">跟踪网站活动</a></h4>
Kafka 的初始用例是将用户活动跟踪管道重建为一组实时发布-订阅源。
这意味着网站活动（浏览网页、搜索或其他的用户操作）将被发布到中心topic，其中每个活动类型有一个topic。
这些订阅源提供一系列用例，包括实时处理、实时监视、对加载到Hadoop或离线数据仓库系统的数据进行离线处理和报告等。
<p>
每个用户浏览网页时都生成了许多活动信息，因此活动跟踪的数据量通常非常大
 
<h4><a id="uses_metrics" href="#uses_metrics">度量</a></h4>
Kafka 通常用于监控数据。这涉及到从分布式应用程序中汇总数据，然后生成可操作的集中数据源。

<h4><a id="uses_logs" href="#uses_logs">日志聚合</a></h4>

Many people use Kafka as a replacement for a log aggregation solution.
Log aggregation typically collects physical log files off servers and puts them in a central place (a file server or HDFS perhaps) for processing.
Kafka abstracts away the details of files and gives a cleaner abstraction of log or event data as a stream of messages.
This allows for lower-latency processing and easier support for multiple data sources and distributed data consumption.

In comparison to log-centric systems like Scribe or Flume, Kafka offers equally good performance, stronger durability guarantees due to replication,
and much lower end-to-end latency.

<h4><a id="uses_streamprocessing" href="#uses_streamprocessing">Stream Processing</a></h4>

Many users of Kafka process data in processing pipelines consisting of multiple stages, where raw input data is consumed from Kafka topics and then
aggregated, enriched, or otherwise transformed into new topics for further consumption or follow-up processing.
For example, a processing pipeline for recommending news articles might crawl article content from RSS feeds and publish it to an "articles" topic;
further processing might normalize or deduplicate this content and published the cleansed article content to a new topic;
a final processing stage might attempt to recommend this content to users.
Such processing pipelines create graphs of real-time data flows based on the individual topics.
Starting in 0.10.0.0, a light-weight but powerful stream processing library called <a href="/documentation/streams">Kafka Streams</a>
is available in Apache Kafka to perform such data processing as described above.
Apart from Kafka Streams, alternative open source stream processing tools include <a href="https://storm.apache.org/">Apache Storm</a> and
<a href="http://samza.apache.org/">Apache Samza</a>.

<h4><a id="uses_eventsourcing" href="#uses_eventsourcing">Event Sourcing</a></h4>

<a href="http://martinfowler.com/eaaDev/EventSourcing.html">Event sourcing</a> is a style of application design where state changes are logged as a
time-ordered sequence of records. Kafka's support for very large stored log data makes it an excellent backend for an application built in this style.

<h4><a id="uses_commitlog" href="#uses_commitlog">Commit Log</a></h4>

Kafka can serve as a kind of external commit-log for a distributed system. The log helps replicate data between nodes and acts as a re-syncing
mechanism for failed nodes to restore their data.
The <a href="/documentation.html#compaction">log compaction</a> feature in Kafka helps support this usage.
In this usage Kafka is similar to <a href="http://zookeeper.apache.org/bookkeeper/">Apache BookKeeper</a> project.
