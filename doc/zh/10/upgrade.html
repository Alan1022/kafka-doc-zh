<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<script>
@@include('js/templateData.js')
<!--#include virtual="js/templateData.js" --></script>

<script id="upgrade-template" type="text/x-handlebars-template">

<h4><a id="upgrade_1_0_0" href="#upgrade_1_0_0">从 0.8.x, 0.9.x, 0.10.0.x, 0.10.1.x, 0.10.2.x, 0.11.0.x 升级到1.0.0</a></h4>
<p>Kafka 1.0.0 介绍了通信协议方面的改变。 遵循下面的滚动升级计划，可以保证您在升级过程中不用停机。
在升级之前，请先查看<a href="#upgrade_100_notable">1.0.0版本中显著的变化</a>。
</p>

<p><b>滚动升级计划：</b></p>

<ol>
    <li> 更新所有代理上的server.properties 并添加以下属性：
    CURRENT_KAFKA_VERSION代表指您要升级的版本。CURRENT_MESSAGE_FORMAT_VERSION代表当前正在使用的消息格式版本。
    如果您以前重写过消息格式版本，则应保留当前值。或者如果您正从0.11.0.x之前的版本升级，则应将current_message_format_version设置为与current_kafka_version匹配的值。    
        <ul>
            <li>inter.broker.protocol.version=CURRENT_KAFKA_VERSION (例如 0.8.2, 0.9.0, 0.10.0, 0.10.1, 0.10.2, 0.11.0)。</li>
            <li>log.message.format.version=CURRENT_MESSAGE_FORMAT_VERSION  (请参阅 <a href="#upgrade_10_performance_impact">升级后在性能方面潜在的影响</a> ，了解有关此配置的详细信息。</li>
        </ul>
	如果您从0.11.0.x升级，且没有重写消息格式，那么您只需要覆盖inter-broker协议格式。
        <ul>
            <li>inter.broker.protocol.version=CURRENT_KAFKA_VERSION (例如 0.8.2, 0.9.0, 0.10.0, 0.10.1, 0.10.2, 0.11.0)。</li>
        </ul>
    </li>
    <li> 一次升级一个代理：关闭代理，更新代码，重新启动代理。 </li>
    <li> 整个群集升级后，通过编辑修改协议版本<code>inter.broker.protocol.version</code> 并将其设置为1.0。
    <li> 重新启动代理，以使新的协议版本生效。</li>
    <li> 如果您按照上面的指示重写了消息格式版本，则需要再执行一次滚动重启才能将其升级到最新版本。一旦所有（或大部分的）consumer升级到0.11.0或更高版本，请将每个代理上的log.message.format.version更改为1.0，然后逐个重启它们。 
    请注意，以前的Scala consumer 不支持0.11中新的消息格式，因此为了避免转换中的性能成本（或者使用<a href="#upgrade_11_exactly_once_semantics">一次语义</a>），必须使用较新的Java consumer 。 </li>
</ol>

<p><b>其他升级说明：</b></p>

<ol>
    <li>如果你可以接受停机，那么你可以把所有的broker关闭，更新代码并重启。系统将默认启动新的协议。 </li>
    <li>在升级broker后，可以随时更新协议版本并重启。这不需要在升级broker后立即进行。更新消息格式版本也是如此。</li>
</ol>

<h5><a id="upgrade_100_notable" href="#upgrade_100_notable">1.0.0中显著的变化</a></h5>
<ul>
    <li>由于功能稳定，所以默认启动删除topic功能。希望保留以前操作的用户请将代理配置<code>delete.topic.enable</code>设置为false。请记住，在topic中删除数据的操作是不可逆的（即没有“撤销删除”操作）。</li>
    <li> 对于可以按时间戳搜索的topic，如果找不到分区的偏移量，则会将该分区显示在搜索结果中，并将偏移量值设置为空。在以前的版本中，这类分区不会显示。这种更改是为了使搜索行为与不支持时间戳搜索的topic相一致。
    <li>如果<code>inter.broker.protocol.version</code>是1.0或更高版本，即使存在脱机日志目录，代理也会一直保持联机，并在实时日志目录上提交副本。由硬件故障导致的IOException，日志目录可能会变为脱机状态。用户需要监控每个代理度量标准<code>offlineLogDirectoryCount</code>来检查是否存在离线日志目录。</li>
    <li>增加了一个可回溯的异常 KafkaStorageException 。 如果客户端的FetchRequest或ProducerRequest的版本不支持KafkaStorageException，则KafkaStorageException将在响应中转换为NotLeaderForPartitionException。</li>
    <li>-XX：在默认的JVM设置中，+ DisableExplicitGC被-XX:+ ExplicitGCInvokesConcurrent替换。在某些情况下，这有助于避免通过直接缓冲区分配本机内存时出现的内存异常。</li>
    <li>重写的<code>handleError</code>方法已经从以下过时类中除去<code>kafka.api</code>：包<code>FetchRequest</code>，<code>GroupCoordinatorRequest</code>，<code>OffsetCommitRequest</code>， <code>OffsetFetchRequest</code>，<code>OffsetRequest</code>，<code>ProducerRequest</code>，和<code>TopicMetadataRequest</code>。这只是为了在代理上使用，但是实际上它已经不再被使用了，实现也没有被维护。只是因为二进制兼容性，保留了一个存根。</li>
    <li>Java客户端和工具现在接受任何字符串作为客户端ID。</li>
    <li><code>kafka-consumer-offset-checker.sh</code>工具已被弃用。使用<code>kafka-consumer-groups.sh</code>来得到consumer group 的详细信息</li>
    <li>SimpleAclAuthorizer默认将拒绝访问日志记录到授权人日志中。</li>
    <li><code>AuthenticationException</code>中的一个子类向客户端报告身份验证失败日志。如果客户端连接失败，并不会重新进行验证 。</li>
    <li>自定义 <code>SaslServer</code> 实现可能会向客户端抛出 <code>SaslAuthenticationException</code> 来提供有关身份验证失败的错误信息。同时应注意在异常信息中，不要向未授权的客户泄露任何安全方面的关键信息。</li>
    <li>向JMX提供版本和提交ID 的<code>app-info</code>将被弃用，由提供这些属性的metrics（度量）来替换。</li>
    <li>Kafka metrics 现在可能包含非数字值。<code>org.apache.kafka.common.Metric#value()</code>已被弃用并返回<code>0.0</code>以最大限度地减少用户读取每个客户端值时系统断开的概率（用户调用 <code>MetricsReporter</code> 或<code>metrics()</code> 来读取）。<code>org.apache.kafka.common.Metric#metricValue()</code>用来检索数字和非数字的度量值</li>
    <li>每个 Kafka 速率指标都有相应的累计计数度量标准，带后缀 <code>-total</code>方便后续处理。 例如， <code>records-consumed-rate</code>对应的度量标准是 <code>records-consumed-total</code>。</li>
    <li>当系统属性<code>kafka_mx4jenable</code> 设置为 <code>true</code>时，Mx4j才会启用。以前它是默认启用的，如果 <code>kafka_mx4jenable</code> 设置为 <code>true</code>，则禁用Mx4j。</li>
    <li>客户端jar 包中的<code>org.apache.kafka.common.security.auth</code>包现在是公有的，已被添加到javadocs中。这个包中的内部类已经移到其他地方了。</li>
    <li>当使用授权且用户对topic没有必备的权限时，broker 返回TOPIC_AUTHORIZATION_FAILED错误表示broker对于已存在的topic无权限。如果用户具有权限但topic不存在，则返回UNKNOWN_TOPIC_OR_PARTITION错误。</li>
    <li>为新的consumer配置config/consumer.properties 文件中的属性。</li>
</ul>

<h5><a id="upgrade_100_new_protocols" href="#upgrade_100_new_protocols">新的版本协议</a></h5>
<ul>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-112%3A+Handle+disk+failure+for+JBOD">KIP-112</a>: LeaderAndIsrRequest v1 引入一个分区字段 <code>is_new</code> 。</li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-112%3A+Handle+disk+failure+for+JBOD">KIP-112</a>: UpdateMetadataRequest v4 引入一个分区字段 <code>offline_replicas</code> 。 </li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-112%3A+Handle+disk+failure+for+JBOD">KIP-112</a>: MetadataResponse v5 引入一个分区字段<code>offline_replicas</code>。 </li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-112%3A+Handle+disk+failure+for+JBOD">KIP-112</a>: ProduceResponse v4 引入了错误代码KafkaStorageException。 </li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-112%3A+Handle+disk+failure+for+JBOD">KIP-112</a>: FetchResponse v6 引入了错误代码KafkaStorageException。 </li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-152+-+Improve+diagnostics+for+SASL+authentication+failures">KIP-152</a>:添加SaslAuthenticate request来报告身份验证失败。当SaslHandshake request版本大于0，将使用此请求。 </li>
</ul>

<h5><a id="upgrade_100_streams" href="#upgrade_100_streams">升级 1.0.0 Kafka Streams 应用程序</a></h5>
<ul>
    <li> 将Streams应用程序从0.11.0升级到1.0.0不需要使用代理。Kafka Streams 1.0.0应用程序可以连接到0.11.0，0.10.2和0.10.1的代理（却不能连接到0.10.0代理）。</li>
    <li> 如果您正在监控 streams 指标，则需要更改一下报告和代码中的指标名称，因为传递指标的层次结构已更改。</li>
    <li> 有些公共的API，如 <code>ProcessorContext#schedule()</code>、<code>Processor#punctuate()</code>、<code>KStreamBuilder</code>和<code>TopologyBuilder</code> 正在被新的API取代。我们建议进行相应的代码更改，在升级时这些改变是细微的，因为新的API看起来非常相似。</li>
    <li> 更多详细信息，请参阅 <a href="/{{version}}/documentation/streams/upgrade-guide#streams_api_changes_100">1.0.0版本中Streams API 的变化。</a> 。</li>
</ul>

<h4><a id="upgrade_11_0_0" href="#upgrade_11_0_0">从 0.8.x, 0.9.x, 0.10.0.x, 0.10.1.x 或 0.10.2.x 升级到 0.11.0.0</a></h4>
<p>Kafka 0.11.0.0 引入了一个新的消息格式版本，在有线协议方面也有变化。 遵循下面的滚动升级计划，可以保证您在升级过程中不用停机。在升级之前，请先查看<a href="#upgrade_1100_notable">0.11.0.0版本中显著的变化</a>。
</p>
<p>从0.10.2 版本开始，Java客户端（生产者和消费者）已经可以与旧代理进行通信，0.11.0版本客户可以与0.10.0及其以上的代理进行通信。但如果代理版本大于0.10.0，则须先升级Kafka集群中的所有代理，然后再升级客户端。0.11.0版本的代理支持0.8.x及其以上的客户端。
</p>
<p><b>对于滚动升级：</b></p>
<ol>
    <li> 更新所有代理上的server.properties并添加以下属性：CURRENT_KAFKA_VERSION指将要升级的版本。CURRENT_MESSAGE_FORMAT_VERSION指当前正在使用的消息格式版本。如果您以前没有重写消息格式，那么应该将CURRENT_MESSAGE_FORMAT_VERSION设置为与CURRENT_KAFKA_VERSION匹配的版本。
        <ul>
            <li>inter.broker.protocol.version=CURRENT_KAFKA_VERSION (例如： 0.8.2，0.9.0，0.10.0，0.10.1 或0.10.2).</li>
            <li>log.message.format.version=CURRENT_MESSAGE_FORMAT_VERSION  （想了解有关此配置的详细信息，请参阅 <a href="#upgrade_10_performance_impact">升级后潜在的性能影响</a>。）</li>
        </ul>
    </li>
    <li> 一次升级一个代理：关闭代理，更新代码并重启。 </li>
    <li> 整个群集升级后，通过编辑修改协议版本<code>inter.broker.protocol.version</code>为0.11.0，但不要更改<code>log.message.format.version</code>。</li>
    <li> 重启代理，以使新的协议版本生效。</li>
    <li> 一旦所有（或大部分）消费者升级到0.11.0及以上版本，则将每个代理的log.message.format.version更改为0.11.0，然后逐一重启它们。请注意，较低版本的Scala消费者不支持新的消息格式，因此为了避免向下转换的性能成本（或者利用<a href="#upgrade_11_exactly_once_semantics">一次语义</a>），必须使用新的Java消费者。</li>
</ol>
<p><b>其他升级说明：</b></p>

<ol>
  <li>如果你可以接受停机，那么你可以把所有的broker关闭，更新代码并重启。系统将默认启动新的协议。</li>
  <li>在升级broker后，可以随时更新协议版本并重启。这不需要在升级broker后立即进行。更新消息格式版本也是如此。</li>
  <li>在更新全局设置<code>log.message.format.version</code>之前，也可以使用主题管理工具（<code>bin/kafka-topics.sh</code>）在各个topic上启用0.11.0消息格式。</li>
  <li>如果要从0.10.0之前的版本升级，则在切换到0.11.0之前，不必先将消息格式更新为0.10.0。</li>
</ol>
<h5><a id="upgrade_1100_streams" href="#upgrade_1100_streams">升级 0.10.2 Kafka Streams 应用程序</a></h5>
<ul>
    <li> 将Streams应用程序从 0.10.2 升级到 0.11.0 不需要使用代理。Kafka Streams 0.11.0应用程序可以连接到0.11.0，0.10.2和0.10.1的代理（却不能连接到0.10.0代理）。</li>
    <li> 如果您自定义配置<code>key.serde</code>，<code>value.serde</code> 和 <code>timestamp.extractor</code>，建议使用替换的配置参数，因为这些配置已被弃用。</li>
    <li> 更多详细信息，请参阅 <a href="/{{version}}/documentation/streams/upgrade-guide#streams_api_changes_0110"> 0.11.0版本中Streams API 的变化</a>。</li>
</ul>
<h5><a id="upgrade_1100_notable" href="#upgrade_1100_notable"> 0.11.0.0版本中显著的变化</a></h5>
<ul>
    <li> 现在默认禁用 Unclean leader选择。这一新的默认值有利于耐用性而非可用性。希望保留原有配置的用户可将代理配置<code>unclean.leader.election.enable</code>改为为<code>true</code>。</li>
    <li> 生产者配置<code>block.on.buffer.full</code>，<code>metadata.fetch.timeout.ms</code> 和<code>timeout.ms</code> 已被删除。他们在 0.9.0.0版本中就被弃用。</li>
    <li><code>offsets.topic.replication.factor</code>配置现在被限制由 topic 自动生成。当群集大小不满足复制因子要求时，topic 内部自动生成将失败并返回 GROUP_COORDINATOR_NOT_AVAILABLE 错误。</li>
    <li> 快速压缩数据时，为提高压缩率，制造商和代理默认使用的压缩块大小为（2 x 32 KB）而不是1 KB。有报告表明：使用较小的块压缩后，数据占用的空间比使用大的块多50%对于这种情况来说，拥有5000个分区的生产者需要额外的315 MB的JVM堆。</li>
    <li> 同样，使用gzip压缩数据时，生产者和代理会将缓冲区大小设置为8 KB而不是1 KB。gzip的默认值过低（512字节）。</li>
    <li> 代理配置 <code>max.message.bytes</code> 现在指批量消息的大小。之前将其应用于批量压缩的消息，或单独应用于未压缩的消息。批量消息可能只包含单个消息，因此大多数情况下，单个消息的大小只能通过批量格式的上限来控制。不过，消息格式转换有一些微妙的含义（详见 <a href="#upgrade_11_message_format">below</a> for more detail）。请注意，代理以前会确保在每个提取请求中至少返回一条消息（无论总分区级别和分区级别的提取大小），但这一行为现在适用于批量消息。</li>
    <li>默认启用GC日志旋转，详情请参阅KAFKA-3754。</li>
    <li>RecordMetadata，MetricName和Cluster类的构造函数已被删除。</li>
    <li>通过提供用户header读写访问，新Headers接口增加了对用户header的支持。</li>
    <li>ProducerRecord和ConsumerRecord通过<code>Headers headers()</code>方法调用新的Headers API。</li>
    <li>ExtendedSerializer和ExtendedDeserializer接口用来来支持头文件的序列化和反序列化。如果配置的串行器和解串器不是上述类，那么头文件将被忽略。</li>
    <li>引入了一个新的配置<code>group.initial.rebalance.delay.ms</code>，该配置指定时间以毫秒为单位。<code>GroupCoordinator</code>将延迟初始消费者以实现再平衡。当有新成员加入group时，将根据<code>group.initial.rebalance.delay.ms</code>的值进行平衡，延迟的时间最高可达<code>max.poll.interval.ms</code>（默认为3秒）。在开发和测试中，为了不延迟执行的时间，可能需要将其设置为0。</li>
    <li>在主题请求的元数据不存在时，<code>org.apache.kafka.common.Cluster#partitionsForTopic</code>、 <code>partitionsForNode</code> 和<code>availablePartitionsForTopic</code>方法会返回一个空列表，而不是<code>null</code> （这被认为是不好的做法）。</li>
    <li>Streams API 的配置参数<code>timestamp.extractor</code>、<code>key.serde</code>和 <code>value.serde</code> 分别被<code>default.timestamp.extractor</code>、<code>default.key.serde</code>和<code>default.value.serde</code>替代。</li>
    <li>当实例RetriableCommitFailedException通过提交回调时，如遇Java消费者<code>commitAsync</code>API中的偏移提交失败，我们不再公布底层原因。更多详细信息，请参阅<a href="https://issues.apache.org/jira/browse/KAFKA-5052">KAFKA-5052</a>。</li>
</ul>
<h5><a id="upgrade_1100_new_protocols" href="#upgrade_1100_new_protocols">新的版本协议</a></h5>
<ul>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-107%3A+Add+purgeDataBefore()+API+in+AdminClient">KIP-107</a>： FetchRequest v5 引入了一个分区字段 <code>log_start_offset</code>。 </li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-107%3A+Add+purgeDataBefore()+API+in+AdminClient">KIP-107</a>：FetchResponse v5 引入了一个分区字段<code>log_start_offset</code>。 </li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-82+-+Add+Record+Headers">KIP-82</a>：ProduceRequest v3 在消息协议中引入了一组包含<code>key</code>字段和<code>value</code>字段的<code>header</code>。</li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-82+-+Add+Record+Headers">KIP-82</a>：FetchResponse v5 在消息协议中引入了一组包含<code>key</code>字段和<code>value</code>字段的<code>header</code>。</li>
</ul>
<h5><a id="upgrade_11_exactly_once_semantics" href="#upgrade_11_exactly_once_semantics">有关一次语义的注记</a></h5>
<p>在生产者方面，Kafka 0.11.0 支持幂等和事务性能力。幂等传递确保消息在单个生产者的生命周期内仅给特定的主题分区传递一次。事务交付允许生产者给多个分区发送数据，这样所有的消息都会被传递成功或失败。这些功能使Kafka符合“恰好一次语义”。有关这些功能的更多详细信息，请参阅用户指南。下面我们将指出一些有关升级群集过程中的特定注意事项。请注意，启用EoS不是必需的，如未使用，不会影响broker的行为。</p>
<ol>
  <li>只有新的Java生产者和消费者支持一次语义。</li>
  <li>这些功能主要取决于<a href="#upgrade_11_message_format">0.11.0的消息格式</a>。在旧版本中使用将导致不被支持的版本错误。</li>
<li>事务状态存储在一个新的内部主题<code>__transaction_state</code>中。在首次使用事务性请求API时才创建此主题。同样地，消费者偏移主题也有几个配置设置用来控制主题。如<code>transaction.state.log.min.isr</code>控制主题的最小ISR。请参阅用户指南中的配置部分以获取完整的选项列表。</li>
  <li>对于安全集群，事务性API需要新的ACL，它可以被<code>bin/kafka-acls.sh</code>工具打开。</li>
  <li>Kafka的EoS引入了新的请求API，并修改了几个现有的API。更多详细信息，请参阅
    <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging#KIP-98-ExactlyOnceDeliveryandTransactionalMessaging-RPCProtocolSummary">KIP-98</a></li>
</ol>
<h5><a id="upgrade_11_message_format" href="#upgrade_11_message_format">有关0.11.0中新消息格式的说明</a></h5>
<p>为了更好地支持生产者的交付语义（见<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging">KIP-98</a>）以及提升复制容错能力（参见<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation">KIP-101</a>），0.11.0消息格式增强了几个主要的功能。虽然新格式包含了更多信息以实现这些改进，但我们已经使批处理格式更有效率。只要每批消息的数量大于2，就可以降低整体开销。然而，对于单批次，可能会有一些轻微的性能影响。请参阅<a href="bit.ly/kafka-eos-perf">这里</a> 以便了解我们对新消息格式初始性能的分析结果。您也可以在<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging#KIP-98-ExactlyOnceDeliveryandTransactionalMessaging-MessageFormat">KIP-98</a>方案中找到更多有关信息格式的细节。
</p>
<p>新消息格式中，一个显著的差异是：未压缩的消息会被存储为一个批次。这会对代理配置<code>max.message.bytes</code>（它限制单个批次的大小）有一些影响。首先，如果一个旧版的客户端使用旧格式生产消息到主题分区，且每个消息都比<code>max.message.bytes</code>小，max.message.bytes，那么通过上述转换合并成单批次后，代理仍可能会拒绝它们。通常，这可能发生在单个消息的聚合大小大于<code>max.message.bytes</code>时。
 There is a similar
  effect for older consumers reading messages down-converted from the new format: if the fetch size is not set at least as large as
  <code>max.message.bytes</code>, the consumer may not be able to make progress even if the individual uncompressed messages are smaller
  than the configured fetch size. This behavior does not impact the Java client for 0.10.1.0 and later since it uses an updated fetch protocol
  which ensures that at least one message can be returned even if it exceeds the fetch size. To get around these problems, you should ensure
  1) that the producer's batch size is not set larger than <code>max.message.bytes</code>, and 2) that the consumer's fetch size is set at
  least as large as <code>max.message.bytes</code>.
</p>
**************
老年消费者阅读从新格式下转换的消息也有类似的效果：如果提取大小没有被设置为至少与 max.message.bytes即使单个未压缩的消息小于配置的获取大小，消费者也可能无法取得进展。此行为不影响Java客户端的0.10.1.0及更高版本，因为它使用更新的获取协议，该协议确保即使超过获取大小也能返回至少一条消息。为了解决这些问题，你应该确保1）生产者的批量大小没有被设置得大于max.message.bytes，并且2）消费者的获取大小被设置为至少与max.message.bytes。

大多数关于升级到0.10.0消息格式对性能影响的讨论 仍然与0.11.0升级有关。这主要影响不使用TLS进行保护的群集，因为在这种情况下“零复制”传输已经不可行。为了避免下变换成本，您应该确保客户应用程序升级到最新的0.11.0客户端。值得注意的是，由于旧消费者在0.11.0.0已经被弃用，它不支持新的消息格式。您必须升级才能使用新消费者使用新的消息格式，而不需要下转换成本。请注意，0.11.0消费者支持与0.10.0经纪商的向上兼容性和向上兼容性，所以可以先在经纪商之前升级客户端。
*********************





<p>Most of the discussion on the performance impact of <a href="#upgrade_10_performance_impact">upgrading to the 0.10.0 message format</a>
  remains pertinent to the 0.11.0 upgrade. This mainly affects clusters that are not secured with TLS since "zero-copy" transfer
  is already not possible in that case. In order to avoid the cost of down-conversion, you should ensure that consumer applications
  are upgraded to the latest 0.11.0 client. Significantly, since the old consumer has been deprecated in 0.11.0.0, it does not support
  the new message format. You must upgrade to use the new consumer to use the new message format without the cost of down-conversion.
  Note that 0.11.0 consumers support backwards compatibility with 0.10.0 brokers and upward, so it is possible to upgrade the
  clients first before the brokers.
</p>

<h4><a id="upgrade_10_2_0" href="#upgrade_10_2_0">Upgrading from 0.8.x, 0.9.x, 0.10.0.x or 0.10.1.x to 0.10.2.0</a></h4>
<p>0.10.2.0 has wire protocol changes. By following the recommended rolling upgrade plan below, you guarantee no downtime during the upgrade.
However, please review the <a href="#upgrade_1020_notable">notable changes in 0.10.2.0</a> before upgrading.
</p>

<p>Starting with version 0.10.2, Java clients (producer and consumer) have acquired the ability to communicate with older brokers. Version 0.10.2
clients can talk to version 0.10.0 or newer brokers. However, if your brokers are older than 0.10.0, you must upgrade all the brokers in the
Kafka cluster before upgrading your clients. Version 0.10.2 brokers support 0.8.x and newer clients.
</p>

<p><b>For a rolling upgrade:</b></p>

<ol>
    <li> Update server.properties file on all brokers and add the following properties:
        <ul>
            <li>inter.broker.protocol.version=CURRENT_KAFKA_VERSION (e.g. 0.8.2, 0.9.0, 0.10.0 or 0.10.1).</li>
            <li>log.message.format.version=CURRENT_KAFKA_VERSION  (See <a href="#upgrade_10_performance_impact">potential performance impact following the upgrade</a> for the details on what this configuration does.)
        </ul>
    </li>
    <li> Upgrade the brokers one at a time: shut down the broker, update the code, and restart it. </li>
    <li> Once the entire cluster is upgraded, bump the protocol version by editing inter.broker.protocol.version and setting it to 0.10.2. </li>
    <li> If your previous message format is 0.10.0, change log.message.format.version to 0.10.2 (this is a no-op as the message format is the same for 0.10.0, 0.10.1 and 0.10.2).
        If your previous message format version is lower than 0.10.0, do not change log.message.format.version yet - this parameter should only change once all consumers have been upgraded to 0.10.0.0 or later.</li>
    <li> Restart the brokers one by one for the new protocol version to take effect. </li>
    <li> If log.message.format.version is still lower than 0.10.0 at this point, wait until all consumers have been upgraded to 0.10.0 or later,
        then change log.message.format.version to 0.10.2 on each broker and restart them one by one. </li>
</ol>

<p><b>Note:</b> If you are willing to accept downtime, you can simply take all the brokers down, update the code and start all of them. They will start with the new protocol by default.

<p><b>Note:</b> Bumping the protocol version and restarting can be done any time after the brokers were upgraded. It does not have to be immediately after.

<h5><a id="upgrade_1020_streams" href="#upgrade_1020_streams">Upgrading a 0.10.1 Kafka Streams Application</a></h5>
<ul>
    <li> Upgrading your Streams application from 0.10.1 to 0.10.2 does not require a broker upgrade.
         A Kafka Streams 0.10.2 application can connect to 0.10.2 and 0.10.1 brokers (it is not possible to connect to 0.10.0 brokers though). </li>
    <li> You need to recompile your code. Just swapping the Kafka Streams library jar file will not work and will break your application. </li>
    <li> If you use a custom (i.e., user implemented) timestamp extractor, you will need to update this code, because the <code>TimestampExtractor</code> interface was changed. </li>
    <li> If you register custom metrics, you will need to update this code, because the <code>StreamsMetric</code> interface was changed. </li>
    <li> See <a href="/{{version}}/documentation/streams/upgrade-guide#streams_api_changes_0102">Streams API changes in 0.10.2</a> for more details. </li>
</ul>

<h5><a id="upgrade_10201_notable" href="#upgrade_10201_notable">Notable changes in 0.10.2.1</a></h5>
<ul>
  <li> The default values for two configurations of the StreamsConfig class were changed to improve the resiliency of Kafka Streams applications. The internal Kafka Streams producer <code>retries</code> default value was changed from 0 to 10. The internal Kafka Streams consumer <code>max.poll.interval.ms</code>  default value was changed from 300000 to <code>Integer.MAX_VALUE</code>.
  </li>
</ul>

<h5><a id="upgrade_1020_notable" href="#upgrade_1020_notable">Notable changes in 0.10.2.0</a></h5>
<ul>
    <li>The Java clients (producer and consumer) have acquired the ability to communicate with older brokers. Version 0.10.2 clients
        can talk to version 0.10.0 or newer brokers. Note that some features are not available or are limited when older brokers
        are used. </li>
    <li>Several methods on the Java consumer may now throw <code>InterruptException</code> if the calling thread is interrupted.
        Please refer to the <code>KafkaConsumer</code> Javadoc for a more in-depth explanation of this change.</li>
    <li>Java consumer now shuts down gracefully. By default, the consumer waits up to 30 seconds to complete pending requests.
        A new close API with timeout has been added to <code>KafkaConsumer</code> to control the maximum wait time.</li>
    <li>Multiple regular expressions separated by commas can be passed to MirrorMaker with the new Java consumer via the --whitelist option. This
        makes the behaviour consistent with MirrorMaker when used the old Scala consumer.</li>
    <li>Upgrading your Streams application from 0.10.1 to 0.10.2 does not require a broker upgrade.
        A Kafka Streams 0.10.2 application can connect to 0.10.2 and 0.10.1 brokers (it is not possible to connect to 0.10.0 brokers though).</li>
    <li>The Zookeeper dependency was removed from the Streams API. The Streams API now uses the Kafka protocol to manage internal topics instead of
        modifying Zookeeper directly. This eliminates the need for privileges to access Zookeeper directly and "StreamsConfig.ZOOKEEPER_CONFIG"
        should not be set in the Streams app any more. If the Kafka cluster is secured, Streams apps must have the required security privileges to create new topics.</li>
    <li>Several new fields including "security.protocol", "connections.max.idle.ms", "retry.backoff.ms", "reconnect.backoff.ms" and "request.timeout.ms" were added to
        StreamsConfig class. User should pay attention to the default values and set these if needed. For more details please refer to <a href="/{{version}}/documentation/#streamsconfigs">3.5 Kafka Streams Configs</a>.</li>
</ul>

<h5><a id="upgrade_1020_new_protocols" href="#upgrade_1020_new_protocols">New Protocol Versions</a></h5>
<ul>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-88%3A+OffsetFetch+Protocol+Update">KIP-88</a>: OffsetFetchRequest v2 supports retrieval of offsets for all topics if the <code>topics</code> array is set to <code>null</code>. </li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-88%3A+OffsetFetch+Protocol+Update">KIP-88</a>: OffsetFetchResponse v2 introduces a top-level <code>error_code</code> field. </li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic">KIP-103</a>: UpdateMetadataRequest v3 introduces a <code>listener_name</code> field to the elements of the <code>end_points</code> array. </li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-108%3A+Create+Topic+Policy">KIP-108</a>: CreateTopicsRequest v1 introduces a <code>validate_only</code> field. </li>
    <li> <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-108%3A+Create+Topic+Policy">KIP-108</a>: CreateTopicsResponse v1 introduces an <code>error_message</code> field to the elements of the <code>topic_errors</code> array. </li>
</ul>

<h4><a id="upgrade_10_1" href="#upgrade_10_1">Upgrading from 0.8.x, 0.9.x or 0.10.0.X to 0.10.1.0</a></h4>
0.10.1.0 has wire protocol changes. By following the recommended rolling upgrade plan below, you guarantee no downtime during the upgrade.
However, please notice the <a href="#upgrade_10_1_breaking">Potential breaking changes in 0.10.1.0</a> before upgrade.
<br>
Note: Because new protocols are introduced, it is important to upgrade your Kafka clusters before upgrading your clients (i.e. 0.10.1.x clients
only support 0.10.1.x or later brokers while 0.10.1.x brokers also support older clients).

<p><b>For a rolling upgrade:</b></p>

<ol>
    <li> Update server.properties file on all brokers and add the following properties:
        <ul>
            <li>inter.broker.protocol.version=CURRENT_KAFKA_VERSION (e.g. 0.8.2.0, 0.9.0.0 or 0.10.0.0).</li>
            <li>log.message.format.version=CURRENT_KAFKA_VERSION  (See <a href="#upgrade_10_performance_impact">potential performance impact following the upgrade</a> for the details on what this configuration does.)
        </ul>
    </li>
    <li> Upgrade the brokers one at a time: shut down the broker, update the code, and restart it. </li>
    <li> Once the entire cluster is upgraded, bump the protocol version by editing inter.broker.protocol.version and setting it to 0.10.1.0. </li>
    <li> If your previous message format is 0.10.0, change log.message.format.version to 0.10.1 (this is a no-op as the message format is the same for both 0.10.0 and 0.10.1).
         If your previous message format version is lower than 0.10.0, do not change log.message.format.version yet - this parameter should only change once all consumers have been upgraded to 0.10.0.0 or later.</li>
    <li> Restart the brokers one by one for the new protocol version to take effect. </li>
    <li> If log.message.format.version is still lower than 0.10.0 at this point, wait until all consumers have been upgraded to 0.10.0 or later,
         then change log.message.format.version to 0.10.1 on each broker and restart them one by one. </li>
</ol>

<p><b>Note:</b> If you are willing to accept downtime, you can simply take all the brokers down, update the code and start all of them. They will start with the new protocol by default.

<p><b>Note:</b> Bumping the protocol version and restarting can be done any time after the brokers were upgraded. It does not have to be immediately after.

<h5><a id="upgrade_10_1_breaking" href="#upgrade_10_1_breaking">Potential breaking changes in 0.10.1.0</a></h5>
<ul>
    <li> The log retention time is no longer based on last modified time of the log segments. Instead it will be based on the largest timestamp of the messages in a log segment.</li>
    <li> The log rolling time is no longer depending on log segment create time. Instead it is now based on the timestamp in the messages. More specifically. if the timestamp of the first message in the segment is T, the log will be rolled out when a new message has a timestamp greater than or equal to T + log.roll.ms </li>
    <li> The open file handlers of 0.10.0 will increase by ~33% because of the addition of time index files for each segment.</li>
    <li> The time index and offset index share the same index size configuration. Since each time index entry is 1.5x the size of offset index entry. User may need to increase log.index.size.max.bytes to avoid potential frequent log rolling. </li>
    <li> Due to the increased number of index files, on some brokers with large amount the log segments (e.g. >15K), the log loading process during the broker startup could be longer. Based on our experiment, setting the num.recovery.threads.per.data.dir to one may reduce the log loading time. </li>
</ul>

<h5><a id="upgrade_1010_streams" href="#upgrade_1010_streams">Upgrading a 0.10.0 Kafka Streams Application</a></h5>
<ul>
    <li> Upgrading your Streams application from 0.10.0 to 0.10.1 does require a <a href="#upgrade_10_1">broker upgrade</a> because a Kafka Streams 0.10.1 application can only connect to 0.10.1 brokers. </li>
    <li> There are couple of API changes, that are not backward compatible (cf. <a href="/{{version}}/documentation/streams/upgrade-guide#streams_api_changes_0101">Streams API changes in 0.10.1</a> for more details).
         Thus, you need to update and recompile your code. Just swapping the Kafka Streams library jar file will not work and will break your application. </li>
</ul>

<h5><a id="upgrade_1010_notable" href="#upgrade_1010_notable">Notable changes in 0.10.1.0</a></h5>
<ul>
    <li> The new Java consumer is no longer in beta and we recommend it for all new development. The old Scala consumers are still supported, but they will be deprecated in the next release
         and will be removed in a future major release. </li>
    <li> The <code>--new-consumer</code>/<code>--new.consumer</code> switch is no longer required to use tools like MirrorMaker and the Console Consumer with the new consumer; one simply
         needs to pass a Kafka broker to connect to instead of the ZooKeeper ensemble. In addition, usage of the Console Consumer with the old consumer has been deprecated and it will be
         removed in a future major release. </li>
    <li> Kafka clusters can now be uniquely identified by a cluster id. It will be automatically generated when a broker is upgraded to 0.10.1.0. The cluster id is available via the kafka.server:type=KafkaServer,name=ClusterId metric and it is part of the Metadata response. Serializers, client interceptors and metric reporters can receive the cluster id by implementing the ClusterResourceListener interface. </li>
    <li> The BrokerState "RunningAsController" (value 4) has been removed. Due to a bug, a broker would only be in this state briefly before transitioning out of it and hence the impact of the removal should be minimal. The recommended way to detect if a given broker is the controller is via the kafka.controller:type=KafkaController,name=ActiveControllerCount metric. </li>
    <li> The new Java Consumer now allows users to search offsets by timestamp on partitions. </li>
    <li> The new Java Consumer now supports heartbeating from a background thread. There is a new configuration
         <code>max.poll.interval.ms</code> which controls the maximum time between poll invocations before the consumer
         will proactively leave the group (5 minutes by default). The value of the configuration
         <code>request.timeout.ms</code> must always be larger than <code>max.poll.interval.ms</code> because this is the maximum
         time that a JoinGroup request can block on the server while the consumer is rebalancing, so we have changed its default
         value to just above 5 minutes. Finally, the default value of <code>session.timeout.ms</code> has been adjusted down to
         10 seconds, and the default value of <code>max.poll.records</code> has been changed to 500.</li>
    <li> When using an Authorizer and a user doesn't have <b>Describe</b> authorization on a topic, the broker will no
         longer return TOPIC_AUTHORIZATION_FAILED errors to requests since this leaks topic names. Instead, the UNKNOWN_TOPIC_OR_PARTITION
         error code will be returned. This may cause unexpected timeouts or delays when using the producer and consumer since
         Kafka clients will typically retry automatically on unknown topic errors. You should consult the client logs if you
         suspect this could be happening.</li>
    <li> Fetch responses have a size limit by default (50 MB for consumers and 10 MB for replication). The existing per partition limits also apply (1 MB for consumers
         and replication). Note that neither of these limits is an absolute maximum as explained in the next point. </li>
    <li> Consumers and replicas can make progress if a message larger than the response/partition size limit is found. More concretely, if the first message in the
         first non-empty partition of the fetch is larger than either or both limits, the message will still be returned. </li>
    <li> Overloaded constructors were added to <code>kafka.api.FetchRequest</code> and <code>kafka.javaapi.FetchRequest</code> to allow the caller to specify the
         order of the partitions (since order is significant in v3). The previously existing constructors were deprecated and the partitions are shuffled before
         the request is sent to avoid starvation issues. </li>
</ul>

<h5><a id="upgrade_1010_new_protocols" href="#upgrade_1010_new_protocols">New Protocol Versions</a></h5>
<ul>
    <li> ListOffsetRequest v1 supports accurate offset search based on timestamps. </li>
    <li> MetadataResponse v2 introduces a new field: "cluster_id". </li>
    <li> FetchRequest v3 supports limiting the response size (in addition to the existing per partition limit), it returns messages
         bigger than the limits if required to make progress and the order of partitions in the request is now significant. </li>
    <li> JoinGroup v1 introduces a new field: "rebalance_timeout". </li>
</ul>

<h4><a id="upgrade_10" href="#upgrade_10">Upgrading from 0.8.x or 0.9.x to 0.10.0.0</a></h4>
0.10.0.0 has <a href="#upgrade_10_breaking">potential breaking changes</a> (please review before upgrading) and possible <a href="#upgrade_10_performance_impact">  performance impact following the upgrade</a>. By following the recommended rolling upgrade plan below, you guarantee no downtime and no performance impact during and following the upgrade.
<br>
Note: Because new protocols are introduced, it is important to upgrade your Kafka clusters before upgrading your clients.
<p/>
<b>Notes to clients with version 0.9.0.0: </b>Due to a bug introduced in 0.9.0.0,
clients that depend on ZooKeeper (old Scala high-level Consumer and MirrorMaker if used with the old consumer) will not
work with 0.10.0.x brokers. Therefore, 0.9.0.0 clients should be upgraded to 0.9.0.1 <b>before</b> brokers are upgraded to
0.10.0.x. This step is not necessary for 0.8.X or 0.9.0.1 clients.

<p><b>For a rolling upgrade:</b></p>

<ol>
    <li> Update server.properties file on all brokers and add the following properties:
         <ul>
         <li>inter.broker.protocol.version=CURRENT_KAFKA_VERSION (e.g. 0.8.2 or 0.9.0.0).</li>
         <li>log.message.format.version=CURRENT_KAFKA_VERSION  (See <a href="#upgrade_10_performance_impact">potential performance impact following the upgrade</a> for the details on what this configuration does.)
         </ul>
    </li>
    <li> Upgrade the brokers. This can be done a broker at a time by simply bringing it down, updating the code, and restarting it. </li>
    <li> Once the entire cluster is upgraded, bump the protocol version by editing inter.broker.protocol.version and setting it to 0.10.0.0. NOTE: You shouldn't touch log.message.format.version yet - this parameter should only change once all consumers have been upgraded to 0.10.0.0 </li>
    <li> Restart the brokers one by one for the new protocol version to take effect. </li>
    <li> Once all consumers have been upgraded to 0.10.0, change log.message.format.version to 0.10.0 on each broker and restart them one by one.
    </li>
</ol>

<p><b>Note:</b> If you are willing to accept downtime, you can simply take all the brokers down, update the code and start all of them. They will start with the new protocol by default.

<p><b>Note:</b> Bumping the protocol version and restarting can be done any time after the brokers were upgraded. It does not have to be immediately after.

<h5><a id="upgrade_10_performance_impact" href="#upgrade_10_performance_impact">Potential performance impact following upgrade to 0.10.0.0</a></h5>
<p>
    The message format in 0.10.0 includes a new timestamp field and uses relative offsets for compressed messages.
    The on disk message format can be configured through log.message.format.version in the server.properties file.
    The default on-disk message format is 0.10.0. If a consumer client is on a version before 0.10.0.0, it only understands
    message formats before 0.10.0. In this case, the broker is able to convert messages from the 0.10.0 format to an earlier format
    before sending the response to the consumer on an older version. However, the broker can't use zero-copy transfer in this case.

    Reports from the Kafka community on the performance impact have shown CPU utilization going from 20% before to 100% after an upgrade, which forced an immediate upgrade of all clients to bring performance back to normal.

    To avoid such message conversion before consumers are upgraded to 0.10.0.0, one can set log.message.format.version to 0.8.2 or 0.9.0 when upgrading the broker to 0.10.0.0. This way, the broker can still use zero-copy transfer to send the data to the old consumers. Once consumers are upgraded, one can change the message format to 0.10.0 on the broker and enjoy the new message format that includes new timestamp and improved compression.

    The conversion is supported to ensure compatibility and can be useful to support a few apps that have not updated to newer clients yet, but is impractical to support all consumer traffic on even an overprovisioned cluster. Therefore, it is critical to avoid the message conversion as much as possible when brokers have been upgraded but the majority of clients have not.
</p>
<p>
    For clients that are upgraded to 0.10.0.0, there is no performance impact.
</p>
<p>
    <b>Note:</b> By setting the message format version, one certifies that all existing messages are on or below that
    message format version. Otherwise consumers before 0.10.0.0 might break. In particular, after the message format
    is set to 0.10.0, one should not change it back to an earlier format as it may break consumers on versions before 0.10.0.0.
</p>
<p>
    <b>Note:</b> Due to the additional timestamp introduced in each message, producers sending small messages may see a
    message throughput degradation because of the increased overhead.
    Likewise, replication now transmits an additional 8 bytes per message.
    If you're running close to the network capacity of your cluster, it's possible that you'll overwhelm the network cards
    and see failures and performance issues due to the overload.
</p>
    <b>Note:</b> If you have enabled compression on producers, you may notice reduced producer throughput and/or
    lower compression rate on the broker in some cases. When receiving compressed messages, 0.10.0
    brokers avoid recompressing the messages, which in general reduces the latency and improves the throughput. In
    certain cases, however, this may reduce the batching size on the producer, which could lead to worse throughput. If this
    happens, users can tune linger.ms and batch.size of the producer for better throughput. In addition, the producer buffer
    used for compressing messages with snappy is smaller than the one used by the broker, which may have a negative
    impact on the compression ratio for the messages on disk. We intend to make this configurable in a future Kafka
    release.
<p>

</p>

<h5><a id="upgrade_10_breaking" href="#upgrade_10_breaking">Potential breaking changes in 0.10.0.0</a></h5>
<ul>
    <li> Starting from Kafka 0.10.0.0, the message format version in Kafka is represented as the Kafka version. For example, message format 0.9.0 refers to the highest message version supported by Kafka 0.9.0. </li>
    <li> Message format 0.10.0 has been introduced and it is used by default. It includes a timestamp field in the messages and relative offsets are used for compressed messages. </li>
    <li> ProduceRequest/Response v2 has been introduced and it is used by default to support message format 0.10.0 </li>
    <li> FetchRequest/Response v2 has been introduced and it is used by default to support message format 0.10.0 </li>
    <li> MessageFormatter interface was changed from <code>def writeTo(key: Array[Byte], value: Array[Byte], output: PrintStream)</code> to
        <code>def writeTo(consumerRecord: ConsumerRecord[Array[Byte], Array[Byte]], output: PrintStream)</code> </li>
    <li> MessageReader interface was changed from <code>def readMessage(): KeyedMessage[Array[Byte], Array[Byte]]</code> to
        <code>def readMessage(): ProducerRecord[Array[Byte], Array[Byte]]</code> </li>
    <li> MessageFormatter's package was changed from <code>kafka.tools</code> to <code>kafka.common</code> </li>
    <li> MessageReader's package was changed from <code>kafka.tools</code> to <code>kafka.common</code> </li>
    <li> MirrorMakerMessageHandler no longer exposes the <code>handle(record: MessageAndMetadata[Array[Byte], Array[Byte]])</code> method as it was never called. </li>
    <li> The 0.7 KafkaMigrationTool is no longer packaged with Kafka. If you need to migrate from 0.7 to 0.10.0, please migrate to 0.8 first and then follow the documented upgrade process to upgrade from 0.8 to 0.10.0. </li>
    <li> The new consumer has standardized its APIs to accept <code>java.util.Collection</code> as the sequence type for method parameters. Existing code may have to be updated to work with the 0.10.0 client library. </li>
    <li> LZ4-compressed message handling was changed to use an interoperable framing specification (LZ4f v1.5.1).
         To maintain compatibility with old clients, this change only applies to Message format 0.10.0 and later.
         Clients that Produce/Fetch LZ4-compressed messages using v0/v1 (Message format 0.9.0) should continue
         to use the 0.9.0 framing implementation. Clients that use Produce/Fetch protocols v2 or later
         should use interoperable LZ4f framing. A list of interoperable LZ4 libraries is available at http://www.lz4.org/
</ul>

<h5><a id="upgrade_10_notable" href="#upgrade_10_notable">Notable changes in 0.10.0.0</a></h5>

<ul>
    <li> Starting from Kafka 0.10.0.0, a new client library named <b>Kafka Streams</b> is available for stream processing on data stored in Kafka topics. This new client library only works with 0.10.x and upward versioned brokers due to message format changes mentioned above. For more information please read <a href="/{{version}}/documentation/streams">Streams documentation</a>.</li>
    <li> The default value of the configuration parameter <code>receive.buffer.bytes</code> is now 64K for the new consumer.</li>
    <li> The new consumer now exposes the configuration parameter <code>exclude.internal.topics</code> to restrict internal topics (such as the consumer offsets topic) from accidentally being included in regular expression subscriptions. By default, it is enabled.</li>
    <li> The old Scala producer has been deprecated. Users should migrate their code to the Java producer included in the kafka-clients JAR as soon as possible. </li>
    <li> The new consumer API has been marked stable. </li>
</ul>

<h4><a id="upgrade_9" href="#upgrade_9">Upgrading from 0.8.0, 0.8.1.X or 0.8.2.X to 0.9.0.0</a></h4>

0.9.0.0 has <a href="#upgrade_9_breaking">potential breaking changes</a> (please review before upgrading) and an inter-broker protocol change from previous versions. This means that upgraded brokers and clients may not be compatible with older versions. It is important that you upgrade your Kafka cluster before upgrading your clients. If you are using MirrorMaker downstream clusters should be upgraded first as well.

<p><b>For a rolling upgrade:</b></p>

<ol>
	<li> Update server.properties file on all brokers and add the following property: inter.broker.protocol.version=0.8.2.X </li>
	<li> Upgrade the brokers. This can be done a broker at a time by simply bringing it down, updating the code, and restarting it. </li>
	<li> Once the entire cluster is upgraded, bump the protocol version by editing inter.broker.protocol.version and setting it to 0.9.0.0.</li>
	<li> Restart the brokers one by one for the new protocol version to take effect </li>
</ol>

<p><b>Note:</b> If you are willing to accept downtime, you can simply take all the brokers down, update the code and start all of them. They will start with the new protocol by default.

<p><b>Note:</b> Bumping the protocol version and restarting can be done any time after the brokers were upgraded. It does not have to be immediately after.

<h5><a id="upgrade_9_breaking" href="#upgrade_9_breaking">Potential breaking changes in 0.9.0.0</a></h5>

<ul>
    <li> Java 1.6 is no longer supported. </li>
    <li> Scala 2.9 is no longer supported. </li>
    <li> Broker IDs above 1000 are now reserved by default to automatically assigned broker IDs. If your cluster has existing broker IDs above that threshold make sure to increase the reserved.broker.max.id broker configuration property accordingly. </li>
    <li> Configuration parameter replica.lag.max.messages was removed. Partition leaders will no longer consider the number of lagging messages when deciding which replicas are in sync. </li>
    <li> Configuration parameter replica.lag.time.max.ms now refers not just to the time passed since last fetch request from replica, but also to time since the replica last caught up. Replicas that are still fetching messages from leaders but did not catch up to the latest messages in replica.lag.time.max.ms will be considered out of sync. </li>
    <li> Compacted topics no longer accept messages without key and an exception is thrown by the producer if this is attempted. In 0.8.x, a message without key would cause the log compaction thread to subsequently complain and quit (and stop compacting all compacted topics). </li>
    <li> MirrorMaker no longer supports multiple target clusters. As a result it will only accept a single --consumer.config parameter. To mirror multiple source clusters, you will need at least one MirrorMaker instance per source cluster, each with its own consumer configuration. </li>
    <li> Tools packaged under <em>org.apache.kafka.clients.tools.*</em> have been moved to <em>org.apache.kafka.tools.*</em>. All included scripts will still function as usual, only custom code directly importing these classes will be affected. </li>
    <li> The default Kafka JVM performance options (KAFKA_JVM_PERFORMANCE_OPTS) have been changed in kafka-run-class.sh. </li>
    <li> The kafka-topics.sh script (kafka.admin.TopicCommand) now exits with non-zero exit code on failure. </li>
    <li> The kafka-topics.sh script (kafka.admin.TopicCommand) will now print a warning when topic names risk metric collisions due to the use of a '.' or '_' in the topic name, and error in the case of an actual collision. </li>
    <li> The kafka-console-producer.sh script (kafka.tools.ConsoleProducer) will use the Java producer instead of the old Scala producer be default, and users have to specify 'old-producer' to use the old producer. </li>
    <li> By default, all command line tools will print all logging messages to stderr instead of stdout. </li>
</ul>

<h5><a id="upgrade_901_notable" href="#upgrade_901_notable">Notable changes in 0.9.0.1</a></h5>

<ul>
    <li> The new broker id generation feature can be disabled by setting broker.id.generation.enable to false. </li>
    <li> Configuration parameter log.cleaner.enable is now true by default. This means topics with a cleanup.policy=compact will now be compacted by default, and 128 MB of heap will be allocated to the cleaner process via log.cleaner.dedupe.buffer.size. You may want to review log.cleaner.dedupe.buffer.size and the other log.cleaner configuration values based on your usage of compacted topics. </li>
    <li> Default value of configuration parameter fetch.min.bytes for the new consumer is now 1 by default. </li>
</ul>

<h5>Deprecations in 0.9.0.0</h5>

<ul>
    <li> Altering topic configuration from the kafka-topics.sh script (kafka.admin.TopicCommand) has been deprecated. Going forward, please use the kafka-configs.sh script (kafka.admin.ConfigCommand) for this functionality. </li>
    <li> The kafka-consumer-offset-checker.sh (kafka.tools.ConsumerOffsetChecker) has been deprecated. Going forward, please use kafka-consumer-groups.sh (kafka.admin.ConsumerGroupCommand) for this functionality. </li>
    <li> The kafka.tools.ProducerPerformance class has been deprecated. Going forward, please use org.apache.kafka.tools.ProducerPerformance for this functionality (kafka-producer-perf-test.sh will also be changed to use the new class). </li>
    <li> The producer config block.on.buffer.full has been deprecated and will be removed in future release. Currently its default value has been changed to false. The KafkaProducer will no longer throw BufferExhaustedException but instead will use max.block.ms value to block, after which it will throw a TimeoutException. If block.on.buffer.full property is set to true explicitly, it will set the max.block.ms to Long.MAX_VALUE and metadata.fetch.timeout.ms will not be honoured</li>
</ul>

<h4><a id="upgrade_82" href="#upgrade_82">Upgrading from 0.8.1 to 0.8.2</a></h4>

0.8.2 is fully compatible with 0.8.1. The upgrade can be done one broker at a time by simply bringing it down, updating the code, and restarting it.

<h4><a id="upgrade_81" href="#upgrade_81">Upgrading from 0.8.0 to 0.8.1</a></h4>

0.8.1 is fully compatible with 0.8. The upgrade can be done one broker at a time by simply bringing it down, updating the code, and restarting it.

<h4><a id="upgrade_7" href="#upgrade_7">Upgrading from 0.7</a></h4>

Release 0.7 is incompatible with newer releases. Major changes were made to the API, ZooKeeper data structures, and protocol, and configuration in order to add replication (Which was missing in 0.7). The upgrade from 0.7 to later versions requires a <a href="https://cwiki.apache.org/confluence/display/KAFKA/Migrating+from+0.7+to+0.8">special tool</a> for migration. This migration can be done without downtime.

</script>

<div class="p-upgrade"></div>
